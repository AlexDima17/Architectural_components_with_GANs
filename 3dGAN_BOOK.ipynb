{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DFW5DHnU0Bzr"
   },
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HPRJ1h7Mlsy9"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "giV3q-hX0kst",
    "outputId": "82f300a4-120b-4bc3-a235-cc1b913a518a"
   },
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install tensorboardx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "adJIrvzp0ZH2"
   },
   "outputs": [],
   "source": [
    "!pip install --pre pytorch-ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "tO3sScBMdOmC",
    "outputId": "5abdee56-aec3-48d2-bc02-1ff97123fcbb"
   },
   "outputs": [],
   "source": [
    "!pip install trimesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ctpFVrl81DZW"
   },
   "outputs": [],
   "source": [
    "import ignite\n",
    "ignite.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fS-V3voddVEN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexandra\\ANACONDA3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Alexandra\\ANACONDA3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Alexandra\\ANACONDA3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import trimesh\n",
    "import trimesh.voxel.creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DQ6OvtKQlszO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexandra\\ANACONDA3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from IPython import display\n",
    "from utils import Logger \n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd.variable import Variable\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexandra\\ANACONDA3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import scipy.ndimage as nd\n",
    "import scipy.io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hGF0yKoq0WOl"
   },
   "outputs": [],
   "source": [
    "from ignite.contrib.handlers import ProgressBar\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.handlers import ModelCheckpoint, Timer\n",
    "from ignite.metrics import RunningAverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZXZ4j0hdvJva"
   },
   "source": [
    "Select device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "X_oX_Bf7u93H",
    "outputId": "e6652ea0-5519-4f11-9d2d-d190b9bb7faf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available(): \n",
    "    print('available')\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    print('no cuda available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tpzLDenqlsz0"
   },
   "source": [
    "##  Preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ntcy1Kp55O8-"
   },
   "outputs": [],
   "source": [
    "def getVoxels(pth, cube_size = 64):\n",
    "    voxels = io.loadmat(pth)['instance']\n",
    "    voxels = np.pad(voxels,(1,1),'constant',constant_values=(0,0))\n",
    "    if cube_size !=32 and cube_size==64:\n",
    "        voxels=nd.zoom(voxels,(2,2,2),mode='constant',order=0)\n",
    "    return voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeDataset(Dataset):\n",
    "    def __init__(self,root,cube_size):\n",
    "        self.root=root\n",
    "        self.listdir = os.listdir(self.root)\n",
    "        self.cube_size = cube_size\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        with open(os.path.join(self.root,self.listdir[index]),\"rb\") as f:\n",
    "            volume = np.asarray(getVoxels(f,self.cube_size),dtype=np.float32)\n",
    "            return torch.FloatTensor(volume)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.listdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ShapeDataset('./stairs/30',64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x286ab678a08>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ru547jHMls0U"
   },
   "source": [
    "## My Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IpULZzMuls0X",
    "outputId": "d7037289-163f-46a4-bdcd-dcc0426a2865",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.DiscriminatorNet'>\n"
     ]
    }
   ],
   "source": [
    "class DiscriminatorNet(torch.nn.Module):\n",
    "    \n",
    "    #3 hidden-layer discriminative nn\n",
    "    \n",
    "    def __init__(self, cube_size = 64):\n",
    "        super(DiscriminatorNet, self).__init__()\n",
    "        self.cube_size = cube_size\n",
    "\n",
    "        padd = (0,0,0)\n",
    "        #if self.cube_size == 32:\n",
    "            #padd = (1,1,1)\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            torch.nn.Conv3d(1, self.cube_size, kernel_size=4, stride=2, bias=False, padding=1),\n",
    "            torch.nn.BatchNorm3d(self.cube_size),\n",
    "            torch.nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            torch.nn.Conv3d(self.cube_size,self.cube_size*2, kernel_size=4, stride=2, bias=False, padding=1),\n",
    "            torch.nn.BatchNorm3d(self.cube_size * 2),\n",
    "            torch.nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            torch.nn.Conv3d(self.cube_size * 2,self.cube_size* 4, kernel_size=4, stride=2, bias=False, padding=1),\n",
    "            torch.nn.BatchNorm3d(self.cube_size * 4),\n",
    "            torch.nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.conv4 = nn.Sequential(\n",
    "            torch.nn.Conv3d(self.cube_size * 4,self.cube_size* 8, kernel_size=4, stride=2, bias=False, padding=1),\n",
    "            torch.nn.BatchNorm3d(self.cube_size * 8),\n",
    "            torch.nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.out = nn.Sequential(\n",
    "            torch.nn.Conv3d(self.cube_size * 8, 1, kernel_size=4, stride=2, bias=False, padding=1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "        \n",
    "print(DiscriminatorNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YMroJGQVls0v"
   },
   "outputs": [],
   "source": [
    "class GeneratorNet(torch.nn.Module):\n",
    "    def __init__(self, cube_size = 64, in_chans = 200):\n",
    "        super(GeneratorNet,self).__init__()\n",
    "        self.cube_size = cube_size\n",
    "        #self.z_space = z_space\n",
    "        self.in_chans = in_chans #latent vector\n",
    "\n",
    "\n",
    "        pad = (0, 0, 0)\n",
    "        #if self.cube_size == 32:\n",
    "            #pad = (1,1,1)\n",
    "\n",
    "        #other version says bias=bias(?check)\n",
    "        self.convT_1 = nn.Sequential(\n",
    "            torch.nn.ConvTranspose3d(self.in_chans, self.cube_size*8, kernel_size=4, stride=2, bias=False, padding=1),\n",
    "            torch.nn.BatchNorm3d(self.cube_size*8),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.convT_2 = nn.Sequential(\n",
    "            torch.nn.ConvTranspose3d(self.cube_size*8,self.cube_size*4, kernel_size=4, stride=2, bias=False, padding=1),\n",
    "            torch.nn.BatchNorm3d(self.cube_size*4),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.convT_3 = nn.Sequential(\n",
    "            torch.nn.ConvTranspose3d(self.cube_size*4,self.cube_size*2, kernel_size=4, stride=2, bias=False, padding=1),\n",
    "            torch.nn.BatchNorm3d(self.cube_size*2),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.convT_4 = nn.Sequential(\n",
    "            torch.nn.ConvTranspose3d(self.cube_size*2,self.cube_size, kernel_size=4, stride=2, bias=False, padding=1),\n",
    "            torch.nn.BatchNorm3d(self.cube_size),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "         \n",
    "        self.out = nn.Sequential(\n",
    "            torch.nn.ConvTranspose3d(self.cube_size,1, kernel_size=4, stride=2, bias=False, padding=1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        x= x.view(-1, self.in_chans, 1, 1, 1)\n",
    "        x = self.convT_1(x)\n",
    "        x = self.convT_2(x)\n",
    "        x = self.convT_3(x)\n",
    "        x = self.convT_4(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iMrGh1oxjoey"
   },
   "outputs": [],
   "source": [
    "def noise_3d():\n",
    "    n = torch.randn(batch_size , z_size, 1,1 )\n",
    "    if torch.cuda.is_available(): return n.cuda()\n",
    "    return n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s72u_oObmZu1"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5SyxjtTdmXBG"
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self,name,device,data_loader,latent_dim,cube_size):\n",
    "        self.name=name\n",
    "        self.device = device\n",
    "        self.data_loader = data_loader\n",
    "        self.latent_dim = latent_dim\n",
    "        self.cube_size = cube_size\n",
    "        #assert self.name = '3dgan' \n",
    "        self.netG = GeneratorNet(self.latent_dim, self.cube_size)\n",
    "        self.netG.to(self.device)\n",
    "        self.netD=DiscriminatorNet(self.cube_size)\n",
    "        self.netD.to(self.device)\n",
    "        self.optim_G = None\n",
    "        self.optim_D = None\n",
    "        self.sceduler_D = None\n",
    "        self.criterion = torch.nn.BCELoss()\n",
    "\n",
    "    def create_optim(self,g_lr, d_lr, alpha=0.5,beta=0.5):\n",
    "        self.optim_G = torch.optim.Adam(self.netG.parameters(), lr= g_lr, betas=(alpha,beta))\n",
    "        self.optim_D = torch.optim.Adam(self.netD.parameters(), lr= d_lr, betas=(alpha,beta))\n",
    "        self.scheduler_D = MultiStepLR(self.optim_D, milestones[500,1000])\n",
    "\n",
    "    def train(self,epochs,d_loss_thresh,log_interval=100,export_interval=10,out_dir='',verbrose=True):\n",
    "        self.netG.train()\n",
    "        self.netD.train()\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "      #batch_time =time.time()\n",
    "          for batch_idx, data in enumerate(self.data_loader):\n",
    "            data = data.to(self.device)\n",
    "\n",
    "            batch_size=data.shape[0]\n",
    "            real_label= torch.Tensor(batch_size).uniform_(0.7,1.2).to(self.device)\n",
    "            real_label= torch.Tensor(batch_size).uniform_(0,0.3).to(self.device)\n",
    " \n",
    "            d_real=self.netD(data)\n",
    "            d_real = d_real.squeeze()\n",
    "            d_real_loss=self.criterion(d_real,real_label)\n",
    "\n",
    "            latent=torch.Tensor(batch_size,self.latent_dim).normal_(0,0.33).to(self.device)\n",
    "\n",
    "            fake=self.netG(latent)\n",
    "            d_fake=netD(fake.detach())\n",
    "            d_fake=d_fake.squeeze()\n",
    "            d_fake_loss =self.criterion(d_fake,fake_label)\n",
    "\n",
    "            d_loss=d_real_loss + d_fake_loss\n",
    "\n",
    "            d_real_acc = torch.ge(d_real.squeeze(), 0.5).float()\n",
    "            d_fake_acc = torch.le(d_fake.squeeze(), 0.5).float()\n",
    "            d_acc=torch.mean(torch.cat((d_real_acc,d_fake_acc),0))\n",
    "\n",
    "        if d_acc <=d_loss_thresh:\n",
    "            self.netD.zero_grad()\n",
    "            d_loss.backward()\n",
    "            self.optim_D.step()\n",
    "\n",
    "        latent = torch.Tensor(batch_size,self.latent_dim).normal_(0,0.33).to(self.device)\n",
    "        fake=self.netG(latent)\n",
    "        d_fake=self.netD(fake)\n",
    "        d_fake=d_fake.squeeze()\n",
    "        g_loss = self.criterion(d_fake,real_label)\n",
    "\n",
    "        self.netD.zero_grad()\n",
    "        self.netG.zero_grad()\n",
    "        g_loss.backward()\n",
    "        self.optim_G.step()\n",
    "\n",
    "        if epoch%export_interval==0:\n",
    "            samples=fake.cpu().data[:8].squeeze().numpy()\n",
    "            utils.save_voxels(samples,out_dir,epoch)\n",
    "        self.scheduler_D.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dRAcFCM0zxOh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Model at 0x286ab67c848>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model('3dModel',device,data_loader,64,32)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "B8XANeiszimu",
    "outputId": "d92d6570-9831-488b-e208-5869364c47d3"
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: './stairs/30\\\\test'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-99076c969aea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-53-b2ee8e096e9e>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epochs, d_loss_thresh, log_interval, export_interval, out_dir, verbrose)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m       \u001b[1;31m#batch_time =time.time()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m           \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ANACONDA3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ANACONDA3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ANACONDA3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ANACONDA3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-b816485f046d>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0mvolume\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetVoxels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcube_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvolume\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: './stairs/30\\\\test'"
     ]
    }
   ],
   "source": [
    "model.train(epochs,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CNJV9jQs4gIl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "ru547jHMls0U"
   ],
   "name": " 3dGAN_BOOK.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
